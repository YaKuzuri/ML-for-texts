{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Тестирование-лучшей-модели\" data-toc-modified-id=\"Тестирование-лучшей-модели-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Тестирование лучшей модели</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Требуется обучить модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок. Значением метрики качества *F1* должно быть не меньше 0.75. \n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "from tqdm import notebook \n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penn2morphy(penntag):\n",
    "    \"\"\" Converts Penn Treebank tags to WordNet. \"\"\"\n",
    "    morphy_tag = {'NN':'n', 'JJ':'a',\n",
    "                  'VB':'v', 'RB':'r'}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return 'n' \n",
    "\n",
    "def lemmatize_sent(text): \n",
    "    \"\"\" Text input is string, returns lowercased strings. \"\"\"\n",
    "    return [wnl.lemmatize(word.lower(), pos=penn2morphy(tag)) \n",
    "            for word, tag in pos_tag(word_tokenize(text))]\n",
    "\n",
    "def lemmatize(text):\n",
    "    return \" \".join(lemmatize_sent(text))\n",
    "\n",
    "def clear_text(text):\n",
    "    return ' '.join(re.sub(r'[^a-zA-z ]', ' ', text).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he', 'be', 'walk', 'to', 'school']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_sent('He is walking to school')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He is walking to school'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_text('He +++5565 is walking to school')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except:\n",
    "    data = pd.read_csv(r'C:\\Users\\yaros\\Новая папка\\toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10161213369158527"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d0eede9e25479eaa57ccf1ea9186c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['lemm_text'] = data['text'].progress_apply(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb41e4c04fea43db882ecba9fb9196a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['lemm_text'] = data['lemm_text'].progress_apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explanation why the edits make under my username hardcore metallica fan be revert they weren t vandalism just closure on some gas after i vote at new york doll fac and please don t remove the template from the talk page since i m retire now'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lemm_text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data['lemm_text']\n",
    "target = data['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "features, target, test_size=0.1, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1017495945583284\n"
     ]
    }
   ],
   "source": [
    "model = DummyClassifier(strategy='stratified')\n",
    "\n",
    "print(cross_val_score(model, features_train, target_train, scoring = 'f1').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7669076326408172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__C': 15}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=200)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", count_tf_idf),\n",
    "        (\"model\", model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "parameters = {'model__C':(5, 10, 15)}\n",
    "grid_lr = GridSearchCV(pipeline, parameters, scoring='f1', cv=3)\n",
    "grid_lr.fit(features_train, target_train)\n",
    "\n",
    "print(grid_lr.best_score_)\n",
    "\n",
    "grid_lr.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08925632762047625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__max_depth': 10, 'model__n_estimators': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=12345)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", count_tf_idf),\n",
    "        (\"model\", model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "parameters = {'model__max_depth':(1, 5, 10), 'model__n_estimators':(1, 10, 20, 30)}\n",
    "grid_forest = GridSearchCV(pipeline, parameters, scoring='f1', cv=3)\n",
    "grid_forest.fit(features_train, target_train)\n",
    "\n",
    "print(grid_forest.best_score_)\n",
    "\n",
    "grid_forest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3592494\ttotal: 545ms\tremaining: 4.91s\n",
      "1:\tlearn: 0.2967167\ttotal: 1.02s\tremaining: 4.06s\n",
      "2:\tlearn: 0.2764759\ttotal: 1.5s\tremaining: 3.51s\n",
      "3:\tlearn: 0.2684851\ttotal: 1.99s\tremaining: 2.98s\n",
      "4:\tlearn: 0.2627348\ttotal: 2.48s\tremaining: 2.48s\n",
      "5:\tlearn: 0.2567165\ttotal: 2.98s\tremaining: 1.99s\n",
      "6:\tlearn: 0.2513139\ttotal: 3.45s\tremaining: 1.48s\n",
      "7:\tlearn: 0.2470820\ttotal: 3.91s\tremaining: 978ms\n",
      "8:\tlearn: 0.2430194\ttotal: 4.39s\tremaining: 487ms\n",
      "9:\tlearn: 0.2406573\ttotal: 4.85s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3647015\ttotal: 479ms\tremaining: 4.31s\n",
      "1:\tlearn: 0.3000873\ttotal: 956ms\tremaining: 3.83s\n",
      "2:\tlearn: 0.2791163\ttotal: 1.41s\tremaining: 3.3s\n",
      "3:\tlearn: 0.2705679\ttotal: 1.87s\tremaining: 2.81s\n",
      "4:\tlearn: 0.2651159\ttotal: 2.34s\tremaining: 2.34s\n",
      "5:\tlearn: 0.2588268\ttotal: 2.8s\tremaining: 1.86s\n",
      "6:\tlearn: 0.2544001\ttotal: 3.26s\tremaining: 1.4s\n",
      "7:\tlearn: 0.2507501\ttotal: 3.72s\tremaining: 931ms\n",
      "8:\tlearn: 0.2476708\ttotal: 4.18s\tremaining: 464ms\n",
      "9:\tlearn: 0.2443541\ttotal: 4.64s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3594871\ttotal: 482ms\tremaining: 4.34s\n",
      "1:\tlearn: 0.2956085\ttotal: 950ms\tremaining: 3.8s\n",
      "2:\tlearn: 0.2766285\ttotal: 1.43s\tremaining: 3.34s\n",
      "3:\tlearn: 0.2683024\ttotal: 1.89s\tremaining: 2.83s\n",
      "4:\tlearn: 0.2626037\ttotal: 2.34s\tremaining: 2.34s\n",
      "5:\tlearn: 0.2566501\ttotal: 2.8s\tremaining: 1.87s\n",
      "6:\tlearn: 0.2514332\ttotal: 3.29s\tremaining: 1.41s\n",
      "7:\tlearn: 0.2472193\ttotal: 3.76s\tremaining: 940ms\n",
      "8:\tlearn: 0.2433680\ttotal: 4.22s\tremaining: 469ms\n",
      "9:\tlearn: 0.2411328\ttotal: 4.67s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3592494\ttotal: 489ms\tremaining: 6.84s\n",
      "1:\tlearn: 0.2967167\ttotal: 949ms\tremaining: 6.17s\n",
      "2:\tlearn: 0.2764759\ttotal: 1.42s\tremaining: 5.66s\n",
      "3:\tlearn: 0.2684851\ttotal: 1.88s\tremaining: 5.16s\n",
      "4:\tlearn: 0.2627348\ttotal: 2.33s\tremaining: 4.66s\n",
      "5:\tlearn: 0.2567165\ttotal: 2.81s\tremaining: 4.21s\n",
      "6:\tlearn: 0.2513139\ttotal: 3.26s\tremaining: 3.73s\n",
      "7:\tlearn: 0.2470820\ttotal: 3.73s\tremaining: 3.27s\n",
      "8:\tlearn: 0.2430194\ttotal: 4.21s\tremaining: 2.81s\n",
      "9:\tlearn: 0.2406573\ttotal: 4.69s\tremaining: 2.34s\n",
      "10:\tlearn: 0.2380223\ttotal: 5.14s\tremaining: 1.87s\n",
      "11:\tlearn: 0.2358471\ttotal: 5.61s\tremaining: 1.4s\n",
      "12:\tlearn: 0.2327093\ttotal: 6.12s\tremaining: 941ms\n",
      "13:\tlearn: 0.2312151\ttotal: 6.59s\tremaining: 471ms\n",
      "14:\tlearn: 0.2295850\ttotal: 7.05s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3647015\ttotal: 487ms\tremaining: 6.82s\n",
      "1:\tlearn: 0.3000873\ttotal: 957ms\tremaining: 6.22s\n",
      "2:\tlearn: 0.2791163\ttotal: 1.42s\tremaining: 5.67s\n",
      "3:\tlearn: 0.2705679\ttotal: 1.88s\tremaining: 5.18s\n",
      "4:\tlearn: 0.2651159\ttotal: 2.35s\tremaining: 4.71s\n",
      "5:\tlearn: 0.2588268\ttotal: 2.84s\tremaining: 4.26s\n",
      "6:\tlearn: 0.2544001\ttotal: 3.37s\tremaining: 3.85s\n",
      "7:\tlearn: 0.2507501\ttotal: 3.87s\tremaining: 3.39s\n",
      "8:\tlearn: 0.2476708\ttotal: 4.36s\tremaining: 2.91s\n",
      "9:\tlearn: 0.2443541\ttotal: 4.84s\tremaining: 2.42s\n",
      "10:\tlearn: 0.2418049\ttotal: 5.3s\tremaining: 1.93s\n",
      "11:\tlearn: 0.2400221\ttotal: 5.78s\tremaining: 1.45s\n",
      "12:\tlearn: 0.2355285\ttotal: 6.26s\tremaining: 963ms\n",
      "13:\tlearn: 0.2340504\ttotal: 6.72s\tremaining: 480ms\n",
      "14:\tlearn: 0.2325445\ttotal: 7.18s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3594871\ttotal: 507ms\tremaining: 7.09s\n",
      "1:\tlearn: 0.2956085\ttotal: 993ms\tremaining: 6.45s\n",
      "2:\tlearn: 0.2766285\ttotal: 1.49s\tremaining: 5.98s\n",
      "3:\tlearn: 0.2683024\ttotal: 1.98s\tremaining: 5.45s\n",
      "4:\tlearn: 0.2626037\ttotal: 2.45s\tremaining: 4.9s\n",
      "5:\tlearn: 0.2566501\ttotal: 2.93s\tremaining: 4.39s\n",
      "6:\tlearn: 0.2514332\ttotal: 3.41s\tremaining: 3.9s\n",
      "7:\tlearn: 0.2472193\ttotal: 3.89s\tremaining: 3.4s\n",
      "8:\tlearn: 0.2433680\ttotal: 4.37s\tremaining: 2.91s\n",
      "9:\tlearn: 0.2411328\ttotal: 4.83s\tremaining: 2.42s\n",
      "10:\tlearn: 0.2384616\ttotal: 5.29s\tremaining: 1.92s\n",
      "11:\tlearn: 0.2362017\ttotal: 5.75s\tremaining: 1.44s\n",
      "12:\tlearn: 0.2347121\ttotal: 6.23s\tremaining: 959ms\n",
      "13:\tlearn: 0.2317622\ttotal: 6.7s\tremaining: 479ms\n",
      "14:\tlearn: 0.2302737\ttotal: 7.16s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3592494\ttotal: 510ms\tremaining: 9.68s\n",
      "1:\tlearn: 0.2967167\ttotal: 990ms\tremaining: 8.91s\n",
      "2:\tlearn: 0.2764759\ttotal: 1.5s\tremaining: 8.51s\n",
      "3:\tlearn: 0.2684851\ttotal: 2.03s\tremaining: 8.13s\n",
      "4:\tlearn: 0.2627348\ttotal: 2.53s\tremaining: 7.58s\n",
      "5:\tlearn: 0.2567165\ttotal: 3.03s\tremaining: 7.07s\n",
      "6:\tlearn: 0.2513139\ttotal: 3.52s\tremaining: 6.54s\n",
      "7:\tlearn: 0.2470820\ttotal: 4s\tremaining: 6s\n",
      "8:\tlearn: 0.2430194\ttotal: 4.47s\tremaining: 5.46s\n",
      "9:\tlearn: 0.2406573\ttotal: 4.99s\tremaining: 4.99s\n",
      "10:\tlearn: 0.2380223\ttotal: 5.49s\tremaining: 4.49s\n",
      "11:\tlearn: 0.2358471\ttotal: 5.96s\tremaining: 3.97s\n",
      "12:\tlearn: 0.2327093\ttotal: 6.44s\tremaining: 3.47s\n",
      "13:\tlearn: 0.2312151\ttotal: 6.92s\tremaining: 2.96s\n",
      "14:\tlearn: 0.2295850\ttotal: 7.4s\tremaining: 2.47s\n",
      "15:\tlearn: 0.2279842\ttotal: 7.88s\tremaining: 1.97s\n",
      "16:\tlearn: 0.2264875\ttotal: 8.37s\tremaining: 1.48s\n",
      "17:\tlearn: 0.2222310\ttotal: 8.85s\tremaining: 983ms\n",
      "18:\tlearn: 0.2208385\ttotal: 9.34s\tremaining: 491ms\n",
      "19:\tlearn: 0.2193348\ttotal: 9.81s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3647015\ttotal: 529ms\tremaining: 10s\n",
      "1:\tlearn: 0.3000873\ttotal: 1.04s\tremaining: 9.34s\n",
      "2:\tlearn: 0.2791163\ttotal: 1.53s\tremaining: 8.66s\n",
      "3:\tlearn: 0.2705679\ttotal: 2.02s\tremaining: 8.07s\n",
      "4:\tlearn: 0.2651159\ttotal: 2.5s\tremaining: 7.51s\n",
      "5:\tlearn: 0.2588268\ttotal: 3s\tremaining: 6.99s\n",
      "6:\tlearn: 0.2544001\ttotal: 3.48s\tremaining: 6.46s\n",
      "7:\tlearn: 0.2507501\ttotal: 3.97s\tremaining: 5.96s\n",
      "8:\tlearn: 0.2476708\ttotal: 4.5s\tremaining: 5.5s\n",
      "9:\tlearn: 0.2443541\ttotal: 5s\tremaining: 5s\n",
      "10:\tlearn: 0.2418049\ttotal: 5.5s\tremaining: 4.5s\n",
      "11:\tlearn: 0.2400221\ttotal: 5.97s\tremaining: 3.98s\n",
      "12:\tlearn: 0.2355285\ttotal: 6.48s\tremaining: 3.49s\n",
      "13:\tlearn: 0.2340504\ttotal: 6.97s\tremaining: 2.98s\n",
      "14:\tlearn: 0.2325445\ttotal: 7.46s\tremaining: 2.48s\n",
      "15:\tlearn: 0.2306240\ttotal: 7.93s\tremaining: 1.98s\n",
      "16:\tlearn: 0.2288004\ttotal: 8.42s\tremaining: 1.49s\n",
      "17:\tlearn: 0.2243109\ttotal: 8.9s\tremaining: 989ms\n",
      "18:\tlearn: 0.2226176\ttotal: 9.42s\tremaining: 496ms\n",
      "19:\tlearn: 0.2210818\ttotal: 9.94s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3594871\ttotal: 487ms\tremaining: 9.26s\n",
      "1:\tlearn: 0.2956085\ttotal: 967ms\tremaining: 8.71s\n",
      "2:\tlearn: 0.2766285\ttotal: 1.45s\tremaining: 8.23s\n",
      "3:\tlearn: 0.2683024\ttotal: 1.94s\tremaining: 7.77s\n",
      "4:\tlearn: 0.2626037\ttotal: 2.43s\tremaining: 7.28s\n",
      "5:\tlearn: 0.2566501\ttotal: 2.9s\tremaining: 6.78s\n",
      "6:\tlearn: 0.2514332\ttotal: 3.38s\tremaining: 6.28s\n",
      "7:\tlearn: 0.2472193\ttotal: 3.86s\tremaining: 5.79s\n",
      "8:\tlearn: 0.2433680\ttotal: 4.34s\tremaining: 5.31s\n",
      "9:\tlearn: 0.2411328\ttotal: 4.83s\tremaining: 4.83s\n",
      "10:\tlearn: 0.2384616\ttotal: 5.3s\tremaining: 4.33s\n",
      "11:\tlearn: 0.2362017\ttotal: 5.76s\tremaining: 3.84s\n",
      "12:\tlearn: 0.2347121\ttotal: 6.25s\tremaining: 3.37s\n",
      "13:\tlearn: 0.2317622\ttotal: 6.76s\tremaining: 2.9s\n",
      "14:\tlearn: 0.2302737\ttotal: 7.24s\tremaining: 2.41s\n",
      "15:\tlearn: 0.2286207\ttotal: 7.72s\tremaining: 1.93s\n",
      "16:\tlearn: 0.2268534\ttotal: 8.23s\tremaining: 1.45s\n",
      "17:\tlearn: 0.2228937\ttotal: 8.74s\tremaining: 971ms\n",
      "18:\tlearn: 0.2214693\ttotal: 9.23s\tremaining: 486ms\n",
      "19:\tlearn: 0.2198845\ttotal: 9.74s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3424032\ttotal: 1.99s\tremaining: 17.9s\n",
      "1:\tlearn: 0.2620899\ttotal: 3.68s\tremaining: 14.7s\n",
      "2:\tlearn: 0.2386558\ttotal: 5.37s\tremaining: 12.5s\n",
      "3:\tlearn: 0.2262882\ttotal: 7s\tremaining: 10.5s\n",
      "4:\tlearn: 0.2182959\ttotal: 8.6s\tremaining: 8.6s\n",
      "5:\tlearn: 0.2089737\ttotal: 10.2s\tremaining: 6.82s\n",
      "6:\tlearn: 0.2045443\ttotal: 11.8s\tremaining: 5.06s\n",
      "7:\tlearn: 0.1993230\ttotal: 13.5s\tremaining: 3.38s\n",
      "8:\tlearn: 0.1960593\ttotal: 15.1s\tremaining: 1.68s\n",
      "9:\tlearn: 0.1927602\ttotal: 16.8s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3565651\ttotal: 1.87s\tremaining: 16.9s\n",
      "1:\tlearn: 0.2677125\ttotal: 3.55s\tremaining: 14.2s\n",
      "2:\tlearn: 0.2436890\ttotal: 5.19s\tremaining: 12.1s\n",
      "3:\tlearn: 0.2273057\ttotal: 6.86s\tremaining: 10.3s\n",
      "4:\tlearn: 0.2184652\ttotal: 8.52s\tremaining: 8.52s\n",
      "5:\tlearn: 0.2113907\ttotal: 10.1s\tremaining: 6.73s\n",
      "6:\tlearn: 0.2068942\ttotal: 11.7s\tremaining: 5s\n",
      "7:\tlearn: 0.2027487\ttotal: 13.3s\tremaining: 3.33s\n",
      "8:\tlearn: 0.1994282\ttotal: 15s\tremaining: 1.66s\n",
      "9:\tlearn: 0.1943585\ttotal: 16.6s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3503796\ttotal: 2.02s\tremaining: 18.2s\n",
      "1:\tlearn: 0.2660216\ttotal: 3.69s\tremaining: 14.8s\n",
      "2:\tlearn: 0.2414244\ttotal: 5.31s\tremaining: 12.4s\n",
      "3:\tlearn: 0.2290874\ttotal: 6.92s\tremaining: 10.4s\n",
      "4:\tlearn: 0.2176997\ttotal: 8.64s\tremaining: 8.64s\n",
      "5:\tlearn: 0.2096752\ttotal: 10.3s\tremaining: 6.86s\n",
      "6:\tlearn: 0.2047224\ttotal: 11.9s\tremaining: 5.11s\n",
      "7:\tlearn: 0.2007848\ttotal: 13.5s\tremaining: 3.37s\n",
      "8:\tlearn: 0.1969068\ttotal: 15.1s\tremaining: 1.67s\n",
      "9:\tlearn: 0.1930377\ttotal: 16.6s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3424032\ttotal: 2.02s\tremaining: 28.3s\n",
      "1:\tlearn: 0.2620899\ttotal: 3.65s\tremaining: 23.7s\n",
      "2:\tlearn: 0.2386558\ttotal: 5.23s\tremaining: 20.9s\n",
      "3:\tlearn: 0.2262882\ttotal: 6.86s\tremaining: 18.9s\n",
      "4:\tlearn: 0.2182959\ttotal: 8.44s\tremaining: 16.9s\n",
      "5:\tlearn: 0.2089737\ttotal: 10.1s\tremaining: 15.1s\n",
      "6:\tlearn: 0.2045443\ttotal: 11.6s\tremaining: 13.2s\n",
      "7:\tlearn: 0.1993230\ttotal: 13.2s\tremaining: 11.6s\n",
      "8:\tlearn: 0.1960593\ttotal: 14.8s\tremaining: 9.85s\n",
      "9:\tlearn: 0.1927602\ttotal: 16.3s\tremaining: 8.15s\n",
      "10:\tlearn: 0.1891764\ttotal: 17.8s\tremaining: 6.48s\n",
      "11:\tlearn: 0.1863997\ttotal: 19.3s\tremaining: 4.83s\n",
      "12:\tlearn: 0.1835335\ttotal: 20.9s\tremaining: 3.21s\n",
      "13:\tlearn: 0.1809194\ttotal: 22.4s\tremaining: 1.6s\n",
      "14:\tlearn: 0.1794199\ttotal: 23.9s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3565651\ttotal: 1.79s\tremaining: 25.1s\n",
      "1:\tlearn: 0.2677125\ttotal: 3.42s\tremaining: 22.2s\n",
      "2:\tlearn: 0.2436890\ttotal: 5.02s\tremaining: 20.1s\n",
      "3:\tlearn: 0.2273057\ttotal: 6.62s\tremaining: 18.2s\n",
      "4:\tlearn: 0.2184652\ttotal: 8.2s\tremaining: 16.4s\n",
      "5:\tlearn: 0.2113907\ttotal: 9.77s\tremaining: 14.7s\n",
      "6:\tlearn: 0.2068942\ttotal: 11.3s\tremaining: 12.9s\n",
      "7:\tlearn: 0.2027487\ttotal: 12.8s\tremaining: 11.2s\n",
      "8:\tlearn: 0.1994282\ttotal: 14.5s\tremaining: 9.65s\n",
      "9:\tlearn: 0.1943585\ttotal: 16.1s\tremaining: 8.05s\n",
      "10:\tlearn: 0.1909548\ttotal: 17.6s\tremaining: 6.4s\n",
      "11:\tlearn: 0.1883725\ttotal: 19.1s\tremaining: 4.78s\n",
      "12:\tlearn: 0.1861166\ttotal: 20.6s\tremaining: 3.17s\n",
      "13:\tlearn: 0.1837519\ttotal: 22.1s\tremaining: 1.58s\n",
      "14:\tlearn: 0.1813810\ttotal: 23.7s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3503796\ttotal: 1.8s\tremaining: 25.2s\n",
      "1:\tlearn: 0.2660216\ttotal: 3.35s\tremaining: 21.8s\n",
      "2:\tlearn: 0.2414244\ttotal: 4.95s\tremaining: 19.8s\n",
      "3:\tlearn: 0.2290874\ttotal: 6.5s\tremaining: 17.9s\n",
      "4:\tlearn: 0.2176997\ttotal: 8.1s\tremaining: 16.2s\n",
      "5:\tlearn: 0.2096752\ttotal: 9.75s\tremaining: 14.6s\n",
      "6:\tlearn: 0.2047224\ttotal: 11.3s\tremaining: 12.9s\n",
      "7:\tlearn: 0.2007848\ttotal: 12.8s\tremaining: 11.2s\n",
      "8:\tlearn: 0.1969068\ttotal: 14.4s\tremaining: 9.59s\n",
      "9:\tlearn: 0.1930377\ttotal: 16s\tremaining: 7.98s\n",
      "10:\tlearn: 0.1898924\ttotal: 17.5s\tremaining: 6.36s\n",
      "11:\tlearn: 0.1872313\ttotal: 19s\tremaining: 4.75s\n",
      "12:\tlearn: 0.1850191\ttotal: 20.6s\tremaining: 3.16s\n",
      "13:\tlearn: 0.1812204\ttotal: 22.1s\tremaining: 1.58s\n",
      "14:\tlearn: 0.1794852\ttotal: 23.5s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3424032\ttotal: 1.86s\tremaining: 35.4s\n",
      "1:\tlearn: 0.2620899\ttotal: 3.47s\tremaining: 31.2s\n",
      "2:\tlearn: 0.2386558\ttotal: 5.05s\tremaining: 28.6s\n",
      "3:\tlearn: 0.2262882\ttotal: 6.61s\tremaining: 26.4s\n",
      "4:\tlearn: 0.2182959\ttotal: 8.15s\tremaining: 24.4s\n",
      "5:\tlearn: 0.2089737\ttotal: 9.71s\tremaining: 22.7s\n",
      "6:\tlearn: 0.2045443\ttotal: 11.2s\tremaining: 20.9s\n",
      "7:\tlearn: 0.1993230\ttotal: 12.8s\tremaining: 19.2s\n",
      "8:\tlearn: 0.1960593\ttotal: 14.3s\tremaining: 17.5s\n",
      "9:\tlearn: 0.1927602\ttotal: 15.9s\tremaining: 15.9s\n",
      "10:\tlearn: 0.1891764\ttotal: 17.5s\tremaining: 14.3s\n",
      "11:\tlearn: 0.1863997\ttotal: 19s\tremaining: 12.7s\n",
      "12:\tlearn: 0.1835335\ttotal: 20.6s\tremaining: 11.1s\n",
      "13:\tlearn: 0.1809194\ttotal: 22.1s\tremaining: 9.46s\n",
      "14:\tlearn: 0.1794199\ttotal: 23.5s\tremaining: 7.84s\n",
      "15:\tlearn: 0.1770284\ttotal: 25.1s\tremaining: 6.29s\n",
      "16:\tlearn: 0.1748312\ttotal: 26.7s\tremaining: 4.71s\n",
      "17:\tlearn: 0.1733534\ttotal: 28.3s\tremaining: 3.14s\n",
      "18:\tlearn: 0.1716212\ttotal: 29.8s\tremaining: 1.57s\n",
      "19:\tlearn: 0.1701346\ttotal: 31.4s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3565651\ttotal: 1.91s\tremaining: 36.3s\n",
      "1:\tlearn: 0.2677125\ttotal: 3.59s\tremaining: 32.3s\n",
      "2:\tlearn: 0.2436890\ttotal: 5.2s\tremaining: 29.5s\n",
      "3:\tlearn: 0.2273057\ttotal: 6.84s\tremaining: 27.4s\n",
      "4:\tlearn: 0.2184652\ttotal: 8.48s\tremaining: 25.4s\n",
      "5:\tlearn: 0.2113907\ttotal: 10s\tremaining: 23.4s\n",
      "6:\tlearn: 0.2068942\ttotal: 11.6s\tremaining: 21.6s\n",
      "7:\tlearn: 0.2027487\ttotal: 13.3s\tremaining: 19.9s\n",
      "8:\tlearn: 0.1994282\ttotal: 14.9s\tremaining: 18.2s\n",
      "9:\tlearn: 0.1943585\ttotal: 16.5s\tremaining: 16.5s\n",
      "10:\tlearn: 0.1909548\ttotal: 18.2s\tremaining: 14.9s\n",
      "11:\tlearn: 0.1883725\ttotal: 19.7s\tremaining: 13.2s\n",
      "12:\tlearn: 0.1861166\ttotal: 21.3s\tremaining: 11.5s\n",
      "13:\tlearn: 0.1837519\ttotal: 22.9s\tremaining: 9.8s\n",
      "14:\tlearn: 0.1813810\ttotal: 24.5s\tremaining: 8.16s\n",
      "15:\tlearn: 0.1790432\ttotal: 26s\tremaining: 6.51s\n",
      "16:\tlearn: 0.1773989\ttotal: 27.5s\tremaining: 4.86s\n",
      "17:\tlearn: 0.1748963\ttotal: 29s\tremaining: 3.23s\n",
      "18:\tlearn: 0.1731110\ttotal: 30.6s\tremaining: 1.61s\n",
      "19:\tlearn: 0.1716830\ttotal: 32.2s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3503796\ttotal: 1.91s\tremaining: 36.3s\n",
      "1:\tlearn: 0.2660216\ttotal: 3.55s\tremaining: 32s\n",
      "2:\tlearn: 0.2414244\ttotal: 5.16s\tremaining: 29.3s\n",
      "3:\tlearn: 0.2290874\ttotal: 6.83s\tremaining: 27.3s\n",
      "4:\tlearn: 0.2176997\ttotal: 8.52s\tremaining: 25.6s\n",
      "5:\tlearn: 0.2096752\ttotal: 10.1s\tremaining: 23.6s\n",
      "6:\tlearn: 0.2047224\ttotal: 11.7s\tremaining: 21.7s\n",
      "7:\tlearn: 0.2007848\ttotal: 13.3s\tremaining: 20s\n",
      "8:\tlearn: 0.1969068\ttotal: 15s\tremaining: 18.3s\n",
      "9:\tlearn: 0.1930377\ttotal: 16.5s\tremaining: 16.5s\n",
      "10:\tlearn: 0.1898924\ttotal: 18.1s\tremaining: 14.8s\n",
      "11:\tlearn: 0.1872313\ttotal: 19.7s\tremaining: 13.1s\n",
      "12:\tlearn: 0.1850191\ttotal: 21.2s\tremaining: 11.4s\n",
      "13:\tlearn: 0.1812204\ttotal: 22.7s\tremaining: 9.73s\n",
      "14:\tlearn: 0.1794852\ttotal: 24.2s\tremaining: 8.05s\n",
      "15:\tlearn: 0.1770465\ttotal: 25.6s\tremaining: 6.41s\n",
      "16:\tlearn: 0.1754169\ttotal: 27.1s\tremaining: 4.79s\n",
      "17:\tlearn: 0.1729987\ttotal: 28.6s\tremaining: 3.18s\n",
      "18:\tlearn: 0.1711191\ttotal: 30.1s\tremaining: 1.58s\n",
      "19:\tlearn: 0.1697926\ttotal: 31.6s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3390980\ttotal: 22.6s\tremaining: 3m 23s\n",
      "1:\tlearn: 0.2471095\ttotal: 45.3s\tremaining: 3m 1s\n",
      "2:\tlearn: 0.2166630\ttotal: 1m 7s\tremaining: 2m 37s\n",
      "3:\tlearn: 0.2042426\ttotal: 1m 30s\tremaining: 2m 15s\n",
      "4:\tlearn: 0.1966992\ttotal: 1m 52s\tremaining: 1m 52s\n",
      "5:\tlearn: 0.1888720\ttotal: 2m 15s\tremaining: 1m 30s\n",
      "6:\tlearn: 0.1843868\ttotal: 2m 37s\tremaining: 1m 7s\n",
      "7:\tlearn: 0.1792145\ttotal: 3m 1s\tremaining: 45.3s\n",
      "8:\tlearn: 0.1755144\ttotal: 3m 24s\tremaining: 22.7s\n",
      "9:\tlearn: 0.1715755\ttotal: 3m 47s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3381739\ttotal: 26.8s\tremaining: 4m\n",
      "1:\tlearn: 0.2461631\ttotal: 55.1s\tremaining: 3m 40s\n",
      "2:\tlearn: 0.2201463\ttotal: 1m 23s\tremaining: 3m 15s\n",
      "3:\tlearn: 0.2065525\ttotal: 1m 54s\tremaining: 2m 51s\n",
      "4:\tlearn: 0.1986082\ttotal: 2m 25s\tremaining: 2m 25s\n",
      "5:\tlearn: 0.1916440\ttotal: 2m 54s\tremaining: 1m 56s\n",
      "6:\tlearn: 0.1855750\ttotal: 3m 22s\tremaining: 1m 26s\n",
      "7:\tlearn: 0.1808795\ttotal: 3m 50s\tremaining: 57.6s\n",
      "8:\tlearn: 0.1758265\ttotal: 4m 18s\tremaining: 28.7s\n",
      "9:\tlearn: 0.1729336\ttotal: 4m 45s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3376836\ttotal: 29.1s\tremaining: 4m 22s\n",
      "1:\tlearn: 0.2546125\ttotal: 55.1s\tremaining: 3m 40s\n",
      "2:\tlearn: 0.2245300\ttotal: 1m 20s\tremaining: 3m 8s\n",
      "3:\tlearn: 0.2067768\ttotal: 1m 49s\tremaining: 2m 44s\n",
      "4:\tlearn: 0.1974292\ttotal: 2m 20s\tremaining: 2m 20s\n",
      "5:\tlearn: 0.1907713\ttotal: 2m 48s\tremaining: 1m 52s\n",
      "6:\tlearn: 0.1847272\ttotal: 3m 17s\tremaining: 1m 24s\n",
      "7:\tlearn: 0.1810397\ttotal: 3m 43s\tremaining: 56s\n",
      "8:\tlearn: 0.1769256\ttotal: 4m 11s\tremaining: 27.9s\n",
      "9:\tlearn: 0.1731791\ttotal: 4m 37s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3390980\ttotal: 30.7s\tremaining: 7m 10s\n",
      "1:\tlearn: 0.2471095\ttotal: 58.7s\tremaining: 6m 21s\n",
      "2:\tlearn: 0.2166630\ttotal: 1m 27s\tremaining: 5m 51s\n",
      "3:\tlearn: 0.2042426\ttotal: 1m 58s\tremaining: 5m 25s\n",
      "4:\tlearn: 0.1966992\ttotal: 2m 28s\tremaining: 4m 57s\n",
      "5:\tlearn: 0.1888720\ttotal: 3m\tremaining: 4m 30s\n",
      "6:\tlearn: 0.1843868\ttotal: 3m 29s\tremaining: 3m 59s\n",
      "7:\tlearn: 0.1792145\ttotal: 3m 58s\tremaining: 3m 28s\n",
      "8:\tlearn: 0.1755144\ttotal: 4m 29s\tremaining: 2m 59s\n",
      "9:\tlearn: 0.1715755\ttotal: 5m\tremaining: 2m 30s\n",
      "10:\tlearn: 0.1676609\ttotal: 5m 28s\tremaining: 1m 59s\n",
      "11:\tlearn: 0.1652321\ttotal: 5m 56s\tremaining: 1m 29s\n",
      "12:\tlearn: 0.1633523\ttotal: 6m 24s\tremaining: 59.1s\n",
      "13:\tlearn: 0.1610882\ttotal: 6m 52s\tremaining: 29.4s\n",
      "14:\tlearn: 0.1585483\ttotal: 7m 20s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3381739\ttotal: 28.8s\tremaining: 6m 42s\n",
      "1:\tlearn: 0.2461631\ttotal: 56.6s\tremaining: 6m 7s\n",
      "2:\tlearn: 0.2201463\ttotal: 1m 24s\tremaining: 5m 37s\n",
      "3:\tlearn: 0.2065525\ttotal: 1m 52s\tremaining: 5m 8s\n",
      "4:\tlearn: 0.1986082\ttotal: 2m 20s\tremaining: 4m 41s\n",
      "5:\tlearn: 0.1916440\ttotal: 2m 48s\tremaining: 4m 12s\n",
      "6:\tlearn: 0.1855750\ttotal: 3m 16s\tremaining: 3m 44s\n",
      "7:\tlearn: 0.1808795\ttotal: 3m 44s\tremaining: 3m 16s\n",
      "8:\tlearn: 0.1758265\ttotal: 4m 12s\tremaining: 2m 48s\n",
      "9:\tlearn: 0.1729336\ttotal: 4m 40s\tremaining: 2m 20s\n",
      "10:\tlearn: 0.1700329\ttotal: 5m 8s\tremaining: 1m 52s\n",
      "11:\tlearn: 0.1672208\ttotal: 5m 37s\tremaining: 1m 24s\n",
      "12:\tlearn: 0.1645747\ttotal: 6m 5s\tremaining: 56.2s\n",
      "13:\tlearn: 0.1622594\ttotal: 6m 33s\tremaining: 28.1s\n",
      "14:\tlearn: 0.1605393\ttotal: 7m\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3376836\ttotal: 25.2s\tremaining: 5m 52s\n",
      "1:\tlearn: 0.2546125\ttotal: 50.2s\tremaining: 5m 26s\n",
      "2:\tlearn: 0.2245300\ttotal: 1m 15s\tremaining: 5m 2s\n",
      "3:\tlearn: 0.2067768\ttotal: 1m 40s\tremaining: 4m 36s\n",
      "4:\tlearn: 0.1974292\ttotal: 2m 5s\tremaining: 4m 11s\n",
      "5:\tlearn: 0.1907713\ttotal: 2m 31s\tremaining: 3m 46s\n",
      "6:\tlearn: 0.1847272\ttotal: 2m 56s\tremaining: 3m 21s\n",
      "7:\tlearn: 0.1810397\ttotal: 3m 21s\tremaining: 2m 56s\n",
      "8:\tlearn: 0.1769256\ttotal: 3m 47s\tremaining: 2m 31s\n",
      "9:\tlearn: 0.1731791\ttotal: 4m 13s\tremaining: 2m 6s\n",
      "10:\tlearn: 0.1703510\ttotal: 4m 39s\tremaining: 1m 41s\n",
      "11:\tlearn: 0.1675054\ttotal: 5m 4s\tremaining: 1m 16s\n",
      "12:\tlearn: 0.1647783\ttotal: 5m 29s\tremaining: 50.7s\n",
      "13:\tlearn: 0.1621476\ttotal: 5m 54s\tremaining: 25.3s\n",
      "14:\tlearn: 0.1597735\ttotal: 6m 20s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3390980\ttotal: 25.6s\tremaining: 8m 6s\n",
      "1:\tlearn: 0.2471095\ttotal: 51s\tremaining: 7m 39s\n",
      "2:\tlearn: 0.2166630\ttotal: 1m 16s\tremaining: 7m 11s\n",
      "3:\tlearn: 0.2042426\ttotal: 1m 41s\tremaining: 6m 46s\n",
      "4:\tlearn: 0.1966992\ttotal: 2m 7s\tremaining: 6m 21s\n",
      "5:\tlearn: 0.1888720\ttotal: 2m 31s\tremaining: 5m 53s\n",
      "6:\tlearn: 0.1843868\ttotal: 2m 56s\tremaining: 5m 28s\n",
      "7:\tlearn: 0.1792145\ttotal: 3m 21s\tremaining: 5m 2s\n",
      "8:\tlearn: 0.1755144\ttotal: 3m 47s\tremaining: 4m 37s\n",
      "9:\tlearn: 0.1715755\ttotal: 4m 12s\tremaining: 4m 12s\n",
      "10:\tlearn: 0.1676609\ttotal: 4m 37s\tremaining: 3m 47s\n",
      "11:\tlearn: 0.1652321\ttotal: 5m 2s\tremaining: 3m 21s\n",
      "12:\tlearn: 0.1633523\ttotal: 5m 28s\tremaining: 2m 57s\n",
      "13:\tlearn: 0.1610882\ttotal: 5m 54s\tremaining: 2m 31s\n",
      "14:\tlearn: 0.1585483\ttotal: 6m 19s\tremaining: 2m 6s\n",
      "15:\tlearn: 0.1565529\ttotal: 6m 44s\tremaining: 1m 41s\n",
      "16:\tlearn: 0.1550104\ttotal: 7m 11s\tremaining: 1m 16s\n",
      "17:\tlearn: 0.1526564\ttotal: 7m 37s\tremaining: 50.9s\n",
      "18:\tlearn: 0.1508129\ttotal: 8m 2s\tremaining: 25.4s\n",
      "19:\tlearn: 0.1494219\ttotal: 8m 29s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3381739\ttotal: 24.9s\tremaining: 7m 53s\n",
      "1:\tlearn: 0.2461631\ttotal: 49.8s\tremaining: 7m 28s\n",
      "2:\tlearn: 0.2201463\ttotal: 1m 15s\tremaining: 7m 8s\n",
      "3:\tlearn: 0.2065525\ttotal: 1m 41s\tremaining: 6m 46s\n",
      "4:\tlearn: 0.1986082\ttotal: 2m 7s\tremaining: 6m 21s\n",
      "5:\tlearn: 0.1916440\ttotal: 2m 32s\tremaining: 5m 54s\n",
      "6:\tlearn: 0.1855750\ttotal: 2m 57s\tremaining: 5m 29s\n",
      "7:\tlearn: 0.1808795\ttotal: 3m 22s\tremaining: 5m 3s\n",
      "8:\tlearn: 0.1758265\ttotal: 3m 46s\tremaining: 4m 37s\n",
      "9:\tlearn: 0.1729336\ttotal: 4m 11s\tremaining: 4m 11s\n",
      "10:\tlearn: 0.1700329\ttotal: 4m 37s\tremaining: 3m 47s\n",
      "11:\tlearn: 0.1672208\ttotal: 5m 3s\tremaining: 3m 22s\n",
      "12:\tlearn: 0.1645747\ttotal: 5m 28s\tremaining: 2m 57s\n",
      "13:\tlearn: 0.1622594\ttotal: 5m 54s\tremaining: 2m 32s\n",
      "14:\tlearn: 0.1605393\ttotal: 6m 20s\tremaining: 2m 6s\n",
      "15:\tlearn: 0.1579511\ttotal: 6m 46s\tremaining: 1m 41s\n",
      "16:\tlearn: 0.1564145\ttotal: 7m 11s\tremaining: 1m 16s\n",
      "17:\tlearn: 0.1545544\ttotal: 7m 37s\tremaining: 50.8s\n",
      "18:\tlearn: 0.1530065\ttotal: 8m 3s\tremaining: 25.5s\n",
      "19:\tlearn: 0.1513123\ttotal: 8m 29s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3376836\ttotal: 24.9s\tremaining: 7m 53s\n",
      "1:\tlearn: 0.2546125\ttotal: 50.6s\tremaining: 7m 35s\n",
      "2:\tlearn: 0.2245300\ttotal: 1m 15s\tremaining: 7m 9s\n",
      "3:\tlearn: 0.2067768\ttotal: 1m 41s\tremaining: 6m 44s\n",
      "4:\tlearn: 0.1974292\ttotal: 2m 6s\tremaining: 6m 19s\n",
      "5:\tlearn: 0.1907713\ttotal: 2m 33s\tremaining: 5m 58s\n",
      "6:\tlearn: 0.1847272\ttotal: 3m 1s\tremaining: 5m 37s\n",
      "7:\tlearn: 0.1810397\ttotal: 3m 29s\tremaining: 5m 13s\n",
      "8:\tlearn: 0.1769256\ttotal: 3m 55s\tremaining: 4m 47s\n",
      "9:\tlearn: 0.1731791\ttotal: 4m 20s\tremaining: 4m 20s\n",
      "10:\tlearn: 0.1703510\ttotal: 4m 45s\tremaining: 3m 53s\n",
      "11:\tlearn: 0.1675054\ttotal: 5m 10s\tremaining: 3m 26s\n",
      "12:\tlearn: 0.1647783\ttotal: 5m 34s\tremaining: 2m 59s\n",
      "13:\tlearn: 0.1621476\ttotal: 5m 57s\tremaining: 2m 33s\n",
      "14:\tlearn: 0.1597735\ttotal: 6m 22s\tremaining: 2m 7s\n",
      "15:\tlearn: 0.1574015\ttotal: 6m 46s\tremaining: 1m 41s\n",
      "16:\tlearn: 0.1555674\ttotal: 7m 10s\tremaining: 1m 15s\n",
      "17:\tlearn: 0.1538362\ttotal: 7m 34s\tremaining: 50.5s\n",
      "18:\tlearn: 0.1522267\ttotal: 7m 59s\tremaining: 25.2s\n",
      "19:\tlearn: 0.1503857\ttotal: 8m 23s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3379309\ttotal: 36.4s\tremaining: 11m 31s\n",
      "1:\tlearn: 0.2453599\ttotal: 1m 13s\tremaining: 11m 4s\n",
      "2:\tlearn: 0.2172617\ttotal: 1m 48s\tremaining: 10m 14s\n",
      "3:\tlearn: 0.2050658\ttotal: 2m 22s\tremaining: 9m 28s\n",
      "4:\tlearn: 0.1970021\ttotal: 2m 56s\tremaining: 8m 49s\n",
      "5:\tlearn: 0.1913741\ttotal: 3m 30s\tremaining: 8m 10s\n",
      "6:\tlearn: 0.1858686\ttotal: 4m 3s\tremaining: 7m 32s\n",
      "7:\tlearn: 0.1806361\ttotal: 4m 36s\tremaining: 6m 55s\n",
      "8:\tlearn: 0.1773314\ttotal: 5m 10s\tremaining: 6m 19s\n",
      "9:\tlearn: 0.1739106\ttotal: 5m 45s\tremaining: 5m 45s\n",
      "10:\tlearn: 0.1712990\ttotal: 6m 18s\tremaining: 5m 9s\n",
      "11:\tlearn: 0.1670633\ttotal: 6m 52s\tremaining: 4m 34s\n",
      "12:\tlearn: 0.1640287\ttotal: 7m 26s\tremaining: 4m\n",
      "13:\tlearn: 0.1614453\ttotal: 8m 2s\tremaining: 3m 26s\n",
      "14:\tlearn: 0.1595746\ttotal: 8m 36s\tremaining: 2m 52s\n",
      "15:\tlearn: 0.1576750\ttotal: 9m 11s\tremaining: 2m 17s\n",
      "16:\tlearn: 0.1561438\ttotal: 9m 46s\tremaining: 1m 43s\n",
      "17:\tlearn: 0.1545066\ttotal: 10m 21s\tremaining: 1m 9s\n",
      "18:\tlearn: 0.1522579\ttotal: 10m 56s\tremaining: 34.6s\n",
      "19:\tlearn: 0.1507976\ttotal: 11m 31s\tremaining: 0us\n",
      "0.6924715005560166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__depth': 10, 'model__n_estimators': 20}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier()\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", count_tf_idf),\n",
    "        (\"model\", model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "parameters = {'model__depth':(1, 5, 10), 'model__n_estimators':(10, 15, 20)}\n",
    "grid_cat = GridSearchCV(pipeline, parameters, scoring='f1', cv=3)\n",
    "grid_cat.fit(features_train, target_train)\n",
    "\n",
    "print(grid_cat.best_score_)\n",
    "\n",
    "grid_cat.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5542505168542124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__max_depth': 10, 'model__n_estimators': 20}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMClassifier()\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", count_tf_idf),\n",
    "        (\"model\", model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "parameters = {'model__max_depth':(1, 5, 10), 'model__n_estimators':(10, 15, 20)}\n",
    "grid_lgbm = GridSearchCV(pipeline, parameters, scoring='f1', cv=3)\n",
    "grid_lgbm.fit(features_train, target_train)\n",
    "\n",
    "print(grid_lgbm.best_score_)\n",
    "\n",
    "grid_lgbm.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.776973457428473\n"
     ]
    }
   ],
   "source": [
    "model = grid_lr.best_estimator_\n",
    "\n",
    "predictions = model.predict(features_test)\n",
    "print(f1_score(target_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалось добится значения F1 почти в 0.777 используя логистическую регрессию, что соответствует требованиям заказчика (F1 > 0.75)."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 55,
    "start_time": "2023-05-17T14:46:41.912Z"
   },
   {
    "duration": 1493,
    "start_time": "2023-05-17T14:46:45.801Z"
   },
   {
    "duration": 3602,
    "start_time": "2023-05-17T14:46:47.297Z"
   },
   {
    "duration": 41,
    "start_time": "2023-05-17T14:46:50.901Z"
   },
   {
    "duration": 25,
    "start_time": "2023-05-17T14:47:08.652Z"
   },
   {
    "duration": 1342,
    "start_time": "2023-05-17T14:57:22.811Z"
   },
   {
    "duration": 928,
    "start_time": "2023-05-17T14:57:24.156Z"
   },
   {
    "duration": 38,
    "start_time": "2023-05-17T14:57:25.086Z"
   },
   {
    "duration": 41,
    "start_time": "2023-05-17T14:57:25.125Z"
   },
   {
    "duration": 13080,
    "start_time": "2023-05-17T14:57:25.168Z"
   },
   {
    "duration": 8,
    "start_time": "2023-05-17T14:57:38.249Z"
   },
   {
    "duration": 67,
    "start_time": "2023-05-17T14:57:38.259Z"
   },
   {
    "duration": 242135,
    "start_time": "2023-05-17T14:57:38.328Z"
   },
   {
    "duration": 12,
    "start_time": "2023-05-17T15:06:42.112Z"
   },
   {
    "duration": 765,
    "start_time": "2023-05-17T15:06:42.126Z"
   },
   {
    "duration": 31,
    "start_time": "2023-05-17T15:06:42.893Z"
   },
   {
    "duration": 14,
    "start_time": "2023-05-17T15:06:42.926Z"
   },
   {
    "duration": 1579,
    "start_time": "2023-05-17T15:07:11.156Z"
   },
   {
    "duration": 3550,
    "start_time": "2023-05-17T15:07:12.737Z"
   },
   {
    "duration": 40,
    "start_time": "2023-05-17T15:07:16.289Z"
   },
   {
    "duration": 15,
    "start_time": "2023-05-17T15:07:16.331Z"
   },
   {
    "duration": 1884,
    "start_time": "2023-05-17T15:07:16.348Z"
   },
   {
    "duration": 164,
    "start_time": "2023-05-17T15:07:18.234Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-17T15:07:18.400Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-17T15:07:31.751Z"
   },
   {
    "duration": 5,
    "start_time": "2023-05-17T15:09:16.530Z"
   },
   {
    "duration": 863,
    "start_time": "2023-05-17T15:09:16.542Z"
   },
   {
    "duration": 50,
    "start_time": "2023-05-17T15:09:17.408Z"
   },
   {
    "duration": 10,
    "start_time": "2023-05-17T15:09:17.460Z"
   },
   {
    "duration": 53,
    "start_time": "2023-05-17T15:09:17.472Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-17T15:09:17.527Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-17T15:09:47.508Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-17T15:10:48.315Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-17T15:11:23.920Z"
   },
   {
    "duration": 795,
    "start_time": "2023-05-17T15:11:23.926Z"
   },
   {
    "duration": 38,
    "start_time": "2023-05-17T15:11:24.723Z"
   },
   {
    "duration": 8,
    "start_time": "2023-05-17T15:11:24.762Z"
   },
   {
    "duration": 10,
    "start_time": "2023-05-17T15:11:24.772Z"
   },
   {
    "duration": 1507,
    "start_time": "2023-05-17T15:12:01.645Z"
   },
   {
    "duration": 3552,
    "start_time": "2023-05-17T15:12:03.154Z"
   },
   {
    "duration": 39,
    "start_time": "2023-05-17T15:12:06.708Z"
   },
   {
    "duration": 14,
    "start_time": "2023-05-17T15:12:06.748Z"
   },
   {
    "duration": 1906,
    "start_time": "2023-05-17T15:12:06.765Z"
   },
   {
    "duration": 11,
    "start_time": "2023-05-17T15:12:08.673Z"
   },
   {
    "duration": 1486,
    "start_time": "2023-05-17T15:15:54.087Z"
   },
   {
    "duration": 1025,
    "start_time": "2023-05-17T15:15:55.576Z"
   },
   {
    "duration": 39,
    "start_time": "2023-05-17T15:15:56.603Z"
   },
   {
    "duration": 39,
    "start_time": "2023-05-17T15:15:56.643Z"
   },
   {
    "duration": 2169,
    "start_time": "2023-05-17T15:15:56.685Z"
   },
   {
    "duration": 21,
    "start_time": "2023-05-17T15:15:58.858Z"
   },
   {
    "duration": 1487,
    "start_time": "2023-05-17T15:17:54.924Z"
   },
   {
    "duration": 938,
    "start_time": "2023-05-17T15:17:56.413Z"
   },
   {
    "duration": 44,
    "start_time": "2023-05-17T15:17:57.354Z"
   },
   {
    "duration": 58,
    "start_time": "2023-05-17T15:17:57.401Z"
   },
   {
    "duration": 2088,
    "start_time": "2023-05-17T15:17:57.461Z"
   },
   {
    "duration": 5,
    "start_time": "2023-05-17T15:17:59.555Z"
   },
   {
    "duration": 2258,
    "start_time": "2023-05-17T23:18:47.419Z"
   },
   {
    "duration": 2292,
    "start_time": "2023-05-17T23:18:49.679Z"
   },
   {
    "duration": 31,
    "start_time": "2023-05-17T23:18:51.973Z"
   },
   {
    "duration": 19,
    "start_time": "2023-05-17T23:18:52.006Z"
   },
   {
    "duration": 2126,
    "start_time": "2023-05-18T15:40:20.037Z"
   },
   {
    "duration": 28,
    "start_time": "2023-05-18T15:45:44.038Z"
   },
   {
    "duration": 2798,
    "start_time": "2023-05-18T15:46:16.516Z"
   },
   {
    "duration": 13,
    "start_time": "2023-05-18T15:47:06.542Z"
   },
   {
    "duration": 13,
    "start_time": "2023-05-18T15:48:49.703Z"
   },
   {
    "duration": 5,
    "start_time": "2023-05-18T15:48:53.621Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-18T15:49:03.798Z"
   },
   {
    "duration": 21,
    "start_time": "2023-05-18T15:50:15.922Z"
   },
   {
    "duration": 8,
    "start_time": "2023-05-18T15:51:47.808Z"
   },
   {
    "duration": 51,
    "start_time": "2023-05-18T15:51:47.818Z"
   },
   {
    "duration": 16,
    "start_time": "2023-05-18T15:51:47.870Z"
   },
   {
    "duration": 2632,
    "start_time": "2023-05-18T15:51:47.895Z"
   },
   {
    "duration": 35,
    "start_time": "2023-05-18T15:51:50.529Z"
   },
   {
    "duration": 20,
    "start_time": "2023-05-18T15:51:50.566Z"
   },
   {
    "duration": 24,
    "start_time": "2023-05-18T15:51:50.588Z"
   },
   {
    "duration": 51,
    "start_time": "2023-05-18T15:51:50.614Z"
   },
   {
    "duration": 25,
    "start_time": "2023-05-18T15:51:50.667Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-18T15:51:50.694Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-18T15:51:50.695Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-18T15:51:50.696Z"
   },
   {
    "duration": 8,
    "start_time": "2023-05-18T15:52:02.453Z"
   },
   {
    "duration": 24,
    "start_time": "2023-05-18T15:52:02.464Z"
   },
   {
    "duration": 20,
    "start_time": "2023-05-18T15:52:02.490Z"
   },
   {
    "duration": 936,
    "start_time": "2023-05-18T15:52:02.512Z"
   },
   {
    "duration": 33,
    "start_time": "2023-05-18T15:52:03.455Z"
   },
   {
    "duration": 43,
    "start_time": "2023-05-18T15:52:03.490Z"
   },
   {
    "duration": 45,
    "start_time": "2023-05-18T15:52:03.548Z"
   },
   {
    "duration": 28,
    "start_time": "2023-05-18T15:52:03.594Z"
   },
   {
    "duration": 108,
    "start_time": "2023-05-18T15:52:03.623Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-18T15:52:03.735Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-18T15:52:03.739Z"
   },
   {
    "duration": 13,
    "start_time": "2023-05-18T15:52:18.141Z"
   },
   {
    "duration": 21,
    "start_time": "2023-05-18T15:52:26.728Z"
   },
   {
    "duration": 36,
    "start_time": "2023-05-18T15:53:07.647Z"
   },
   {
    "duration": 29,
    "start_time": "2023-05-18T15:53:32.651Z"
   },
   {
    "duration": 7,
    "start_time": "2023-05-18T15:53:35.653Z"
   },
   {
    "duration": 5,
    "start_time": "2023-05-18T15:53:36.912Z"
   },
   {
    "duration": 60,
    "start_time": "2023-05-18T15:54:09.249Z"
   },
   {
    "duration": 5,
    "start_time": "2023-05-18T15:54:10.885Z"
   },
   {
    "duration": 7,
    "start_time": "2023-05-18T15:54:11.793Z"
   },
   {
    "duration": 5,
    "start_time": "2023-05-18T15:54:34.398Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-18T15:54:35.942Z"
   },
   {
    "duration": 9,
    "start_time": "2023-05-18T15:56:50.143Z"
   },
   {
    "duration": 9,
    "start_time": "2023-05-18T15:56:50.154Z"
   },
   {
    "duration": 7,
    "start_time": "2023-05-18T15:56:50.165Z"
   },
   {
    "duration": 943,
    "start_time": "2023-05-18T15:56:50.174Z"
   },
   {
    "duration": 47,
    "start_time": "2023-05-18T15:56:51.128Z"
   },
   {
    "duration": 7,
    "start_time": "2023-05-18T15:56:51.177Z"
   },
   {
    "duration": 11,
    "start_time": "2023-05-18T15:56:51.185Z"
   },
   {
    "duration": 34,
    "start_time": "2023-05-18T15:56:51.197Z"
   },
   {
    "duration": 32,
    "start_time": "2023-05-18T15:56:51.240Z"
   },
   {
    "duration": 173,
    "start_time": "2023-05-18T15:56:51.274Z"
   },
   {
    "duration": 5,
    "start_time": "2023-05-18T15:56:51.448Z"
   },
   {
    "duration": 10,
    "start_time": "2023-05-18T15:56:51.455Z"
   },
   {
    "duration": 10,
    "start_time": "2023-05-18T15:57:17.954Z"
   },
   {
    "duration": 15,
    "start_time": "2023-05-18T15:57:17.966Z"
   },
   {
    "duration": 9,
    "start_time": "2023-05-18T15:57:17.983Z"
   },
   {
    "duration": 926,
    "start_time": "2023-05-18T15:57:17.995Z"
   },
   {
    "duration": 33,
    "start_time": "2023-05-18T15:57:18.922Z"
   },
   {
    "duration": 28,
    "start_time": "2023-05-18T15:57:18.957Z"
   },
   {
    "duration": 54,
    "start_time": "2023-05-18T15:57:18.986Z"
   },
   {
    "duration": 27,
    "start_time": "2023-05-18T15:57:19.042Z"
   },
   {
    "duration": 31,
    "start_time": "2023-05-18T15:57:19.071Z"
   },
   {
    "duration": 83,
    "start_time": "2023-05-18T15:57:19.105Z"
   },
   {
    "duration": 50,
    "start_time": "2023-05-18T15:57:19.190Z"
   },
   {
    "duration": 6,
    "start_time": "2023-05-18T15:57:19.243Z"
   },
   {
    "duration": 9,
    "start_time": "2023-05-18T15:58:20.049Z"
   },
   {
    "duration": 10,
    "start_time": "2023-05-18T15:58:20.060Z"
   },
   {
    "duration": 16,
    "start_time": "2023-05-18T15:58:20.071Z"
   },
   {
    "duration": 889,
    "start_time": "2023-05-18T15:58:20.089Z"
   },
   {
    "duration": 55,
    "start_time": "2023-05-18T15:58:20.982Z"
   },
   {
    "duration": 7,
    "start_time": "2023-05-18T15:58:21.040Z"
   },
   {
    "duration": 26,
    "start_time": "2023-05-18T15:58:21.049Z"
   },
   {
    "duration": 20,
    "start_time": "2023-05-18T15:58:21.077Z"
   },
   {
    "duration": 37,
    "start_time": "2023-05-18T15:58:21.098Z"
   },
   {
    "duration": 120,
    "start_time": "2023-05-18T15:58:21.137Z"
   },
   {
    "duration": 6,
    "start_time": "2023-05-18T15:58:21.259Z"
   },
   {
    "duration": 8,
    "start_time": "2023-05-18T15:58:21.267Z"
   },
   {
    "duration": 74,
    "start_time": "2023-05-18T15:58:21.277Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-18T15:58:21.354Z"
   },
   {
    "duration": 1684,
    "start_time": "2023-05-18T16:04:56.650Z"
   },
   {
    "duration": 1421,
    "start_time": "2023-05-18T16:04:58.336Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-18T16:04:59.759Z"
   },
   {
    "duration": 963,
    "start_time": "2023-05-18T16:04:59.765Z"
   },
   {
    "duration": 39,
    "start_time": "2023-05-18T16:05:00.730Z"
   },
   {
    "duration": 23,
    "start_time": "2023-05-18T16:05:00.771Z"
   },
   {
    "duration": 42,
    "start_time": "2023-05-18T16:05:00.796Z"
   },
   {
    "duration": 3087,
    "start_time": "2023-05-18T16:05:00.839Z"
   },
   {
    "duration": 596515,
    "start_time": "2023-05-18T16:05:03.932Z"
   },
   {
    "duration": 6,
    "start_time": "2023-05-18T16:15:00.452Z"
   },
   {
    "duration": 114,
    "start_time": "2023-05-18T16:15:00.460Z"
   },
   {
    "duration": 76,
    "start_time": "2023-05-18T16:15:00.576Z"
   },
   {
    "duration": 114,
    "start_time": "2023-05-18T16:15:00.654Z"
   },
   {
    "duration": 7318,
    "start_time": "2023-05-18T16:15:00.770Z"
   },
   {
    "duration": 154,
    "start_time": "2023-05-18T16:15:08.090Z"
   },
   {
    "duration": 219288,
    "start_time": "2023-05-18T16:15:08.246Z"
   },
   {
    "duration": 22519,
    "start_time": "2023-05-18T16:18:47.536Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-18T16:41:18.156Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-18T16:41:18.158Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-18T16:41:18.159Z"
   },
   {
    "duration": 594521,
    "start_time": "2023-05-18T16:41:25.093Z"
   },
   {
    "duration": 1758,
    "start_time": "2023-05-18T17:37:45.895Z"
   },
   {
    "duration": 1423,
    "start_time": "2023-05-18T17:37:47.655Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-18T17:37:49.080Z"
   },
   {
    "duration": 867,
    "start_time": "2023-05-18T17:37:49.085Z"
   },
   {
    "duration": 31,
    "start_time": "2023-05-18T17:37:49.955Z"
   },
   {
    "duration": 24,
    "start_time": "2023-05-18T17:37:49.989Z"
   },
   {
    "duration": 41,
    "start_time": "2023-05-18T17:37:50.015Z"
   },
   {
    "duration": 2836,
    "start_time": "2023-05-18T17:37:50.058Z"
   },
   {
    "duration": 623759,
    "start_time": "2023-05-18T17:37:52.896Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-18T17:48:16.658Z"
   },
   {
    "duration": 29,
    "start_time": "2023-05-18T17:48:16.665Z"
   },
   {
    "duration": 31,
    "start_time": "2023-05-18T17:48:16.696Z"
   },
   {
    "duration": 77,
    "start_time": "2023-05-18T17:48:16.732Z"
   },
   {
    "duration": 6,
    "start_time": "2023-05-18T17:48:16.812Z"
   },
   {
    "duration": 195,
    "start_time": "2023-05-18T17:48:16.819Z"
   },
   {
    "duration": 133,
    "start_time": "2023-05-18T17:48:17.015Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-18T17:48:17.149Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-18T17:48:17.151Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-18T17:48:17.152Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-18T17:48:17.153Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-18T17:50:08.099Z"
   },
   {
    "duration": 1753,
    "start_time": "2023-05-18T17:50:32.853Z"
   },
   {
    "duration": 1723,
    "start_time": "2023-05-18T17:50:34.608Z"
   },
   {
    "duration": 6,
    "start_time": "2023-05-18T17:50:36.334Z"
   },
   {
    "duration": 993,
    "start_time": "2023-05-18T17:50:36.342Z"
   },
   {
    "duration": 34,
    "start_time": "2023-05-18T17:50:37.338Z"
   },
   {
    "duration": 15,
    "start_time": "2023-05-18T17:50:37.373Z"
   },
   {
    "duration": 22,
    "start_time": "2023-05-18T17:50:37.389Z"
   },
   {
    "duration": 3118,
    "start_time": "2023-05-18T17:50:37.413Z"
   },
   {
    "duration": 589713,
    "start_time": "2023-05-18T17:50:40.539Z"
   },
   {
    "duration": 5,
    "start_time": "2023-05-18T18:00:30.254Z"
   },
   {
    "duration": 39,
    "start_time": "2023-05-18T18:00:30.261Z"
   },
   {
    "duration": 40,
    "start_time": "2023-05-18T18:00:30.302Z"
   },
   {
    "duration": 59,
    "start_time": "2023-05-18T18:00:30.344Z"
   },
   {
    "duration": 8,
    "start_time": "2023-05-18T18:00:30.406Z"
   },
   {
    "duration": 204,
    "start_time": "2023-05-18T18:00:30.416Z"
   },
   {
    "duration": 139,
    "start_time": "2023-05-18T18:00:30.624Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-18T18:00:30.765Z"
   },
   {
    "duration": 1,
    "start_time": "2023-05-18T18:00:30.765Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-18T18:00:30.766Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-18T18:00:30.768Z"
   },
   {
    "duration": 20,
    "start_time": "2023-05-18T18:11:12.926Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-18T18:11:29.686Z"
   },
   {
    "duration": 12,
    "start_time": "2023-05-18T18:11:40.851Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-18T18:15:30.041Z"
   },
   {
    "duration": 41901,
    "start_time": "2023-05-18T18:16:23.693Z"
   },
   {
    "duration": 5,
    "start_time": "2023-05-18T18:17:07.483Z"
   },
   {
    "duration": 255900,
    "start_time": "2023-05-18T18:17:09.445Z"
   },
   {
    "duration": 43,
    "start_time": "2023-05-18T18:21:25.348Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-18T18:21:25.392Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-18T18:21:25.394Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-18T18:21:25.395Z"
   },
   {
    "duration": 919144,
    "start_time": "2023-05-18T18:28:55.189Z"
   },
   {
    "duration": 255572,
    "start_time": "2023-05-18T18:44:14.338Z"
   },
   {
    "duration": 3881558,
    "start_time": "2023-05-18T18:48:29.911Z"
   },
   {
    "duration": 6024319,
    "start_time": "2023-05-18T19:53:11.472Z"
   },
   {
    "duration": 42,
    "start_time": "2023-05-18T21:33:35.793Z"
   },
   {
    "duration": 6043,
    "start_time": "2023-05-18T21:35:25.985Z"
   },
   {
    "duration": 6095,
    "start_time": "2023-05-18T21:36:35.694Z"
   },
   {
    "duration": 14,
    "start_time": "2023-05-18T21:42:49.817Z"
   },
   {
    "duration": 121517,
    "start_time": "2023-05-18T21:44:01.739Z"
   },
   {
    "duration": 788,
    "start_time": "2023-05-18T21:50:25.796Z"
   },
   {
    "duration": 3326,
    "start_time": "2023-05-19T07:23:45.098Z"
   },
   {
    "duration": 1952,
    "start_time": "2023-05-19T07:23:48.428Z"
   },
   {
    "duration": 16,
    "start_time": "2023-05-19T07:23:50.390Z"
   },
   {
    "duration": 3688,
    "start_time": "2023-05-19T07:23:50.414Z"
   },
   {
    "duration": 43,
    "start_time": "2023-05-19T07:23:54.106Z"
   },
   {
    "duration": 13,
    "start_time": "2023-05-19T07:23:54.152Z"
   },
   {
    "duration": 45,
    "start_time": "2023-05-19T07:23:54.167Z"
   },
   {
    "duration": 4080,
    "start_time": "2023-05-19T07:23:54.215Z"
   },
   {
    "duration": 831374,
    "start_time": "2023-05-19T07:23:58.305Z"
   },
   {
    "duration": 18,
    "start_time": "2023-05-19T07:37:49.687Z"
   },
   {
    "duration": 23,
    "start_time": "2023-05-19T07:37:49.709Z"
   },
   {
    "duration": 5,
    "start_time": "2023-05-19T07:37:49.734Z"
   },
   {
    "duration": 81,
    "start_time": "2023-05-19T07:37:49.741Z"
   },
   {
    "duration": 7,
    "start_time": "2023-05-19T07:37:49.826Z"
   },
   {
    "duration": 269,
    "start_time": "2023-05-19T07:37:49.835Z"
   },
   {
    "duration": 1184378,
    "start_time": "2023-05-19T07:37:50.115Z"
   },
   {
    "duration": 340414,
    "start_time": "2023-05-19T07:57:34.497Z"
   },
   {
    "duration": 5793574,
    "start_time": "2023-05-19T08:03:14.921Z"
   },
   {
    "duration": 15146768,
    "start_time": "2023-05-19T09:39:48.498Z"
   },
   {
    "duration": 1477,
    "start_time": "2023-05-19T13:52:15.268Z"
   },
   {
    "duration": 112184,
    "start_time": "2023-05-19T16:52:42.829Z"
   },
   {
    "duration": 1933,
    "start_time": "2023-05-20T16:07:14.171Z"
   },
   {
    "duration": 1377,
    "start_time": "2023-05-20T16:07:16.106Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-20T16:07:17.485Z"
   },
   {
    "duration": 3285,
    "start_time": "2023-05-20T16:07:17.490Z"
   },
   {
    "duration": 32,
    "start_time": "2023-05-20T16:07:20.778Z"
   },
   {
    "duration": 8,
    "start_time": "2023-05-20T16:07:20.812Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-20T16:07:20.822Z"
   },
   {
    "duration": 2549,
    "start_time": "2023-05-20T16:07:20.828Z"
   },
   {
    "duration": 567521,
    "start_time": "2023-05-20T16:07:23.379Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-20T16:16:50.902Z"
   },
   {
    "duration": 16,
    "start_time": "2023-05-20T16:16:50.907Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-20T16:16:50.925Z"
   },
   {
    "duration": 72,
    "start_time": "2023-05-20T16:16:50.931Z"
   },
   {
    "duration": 8,
    "start_time": "2023-05-20T16:16:51.007Z"
   },
   {
    "duration": 246,
    "start_time": "2023-05-20T16:16:51.017Z"
   },
   {
    "duration": 941100,
    "start_time": "2023-05-20T16:16:51.265Z"
   },
   {
    "duration": 107860,
    "start_time": "2023-05-20T16:32:32.367Z"
   },
   {
    "duration": 683,
    "start_time": "2023-05-20T16:34:20.229Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
